#!/usr/bin/python3

from nltk.tokenize import word_tokenize

sentence = "Jim is bringing his bulldog to eat at Friendlys?"
tokens = word_tokenize(sentence)
print(tokens)
